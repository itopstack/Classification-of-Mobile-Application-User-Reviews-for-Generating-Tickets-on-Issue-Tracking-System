{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0520 15:39:11.145781 4611618240 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare actual similarity data\n",
    "data_xlsx = pd.read_excel('./similarity_manually_label.xlsx', 'Sheet1', index_col=0)\n",
    "actual_matrix = np.array(data_xlsx.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base and test data\n",
    "with open('./text_similarity_base.json') as data_file:    \n",
    "    text_similarity_base = json.load(data_file)\n",
    "    \n",
    "with open('./text_similarity_test.json') as data_file:    \n",
    "    text_similarity_test = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base and test data frames\n",
    "base_df = pd.DataFrame.from_dict(text_similarity_base, orient='columns')\n",
    "test_df = pd.DataFrame.from_dict(text_similarity_test, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kittisakp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text pre-processing functions\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [item for item in tokens if item not in stopwords]\n",
    "\n",
    "def keep_alphabetic(tokens):\n",
    "    return [item for item in tokens if item.isalpha()]\n",
    "\n",
    "def reduce_lengthening(tokens):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return [pattern.sub(r\"\\1\\1\", item) for item in tokens]\n",
    "\n",
    "'''lowercase, punctuation, remove stopwords, only alphabetic, reduce lengthening, stem'''\n",
    "def normalize(text):\n",
    "    lower_text_without_punctuation = text.lower().translate(remove_punctuation_map)\n",
    "    return ' '.join(\n",
    "                stem_tokens(\n",
    "                reduce_lengthening(\n",
    "                keep_alphabetic(\n",
    "                remove_stopwords(\n",
    "                tokenize(\n",
    "                lower_text_without_punctuation))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleansing\n",
    "base_df['normalized_text'] = base_df['text'].apply(lambda text: normalize(text))\n",
    "test_df['normalized_text'] = test_df['text'].apply(lambda text: normalize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "thresholds = [\n",
    "    0,\n",
    "    0.1,\n",
    "    0.2,\n",
    "    0.3,\n",
    "    0.4,\n",
    "    0.5,\n",
    "    0.6,\n",
    "    0.7,\n",
    "    0.75,\n",
    "    0.76,\n",
    "    0.77,\n",
    "    0.78,\n",
    "    0.79,\n",
    "    0.8,\n",
    "    0.9,\n",
    "    1\n",
    "]\n",
    "\n",
    "base_sentences = base_df['normalized_text'].values\n",
    "test_sentences = test_df['normalized_text'].values\n",
    "base_count = len(base_sentences)\n",
    "test_count = len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensroflow hub module for Universal sentence Encoder\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0520 15:40:21.697924 4611618240 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(texts):\n",
    "    if type(texts) is str:\n",
    "        texts = [texts]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        return sess.run(embed(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    mag1 = np.linalg.norm(v1)\n",
    "    mag2 = np.linalg.norm(v2)\n",
    "    if (not mag1) or (not mag2):\n",
    "        return 0\n",
    "    return np.dot(v1, v2) / (mag1 * mag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0520 15:41:12.798565 4611618240 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0520 15:41:22.793359 4611618240 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "base_vector = get_features(base_sentences)\n",
    "test_vector = get_features(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(threshold):    \n",
    "    predict_matrix = np.array([[None for j in range(test_count)] for i in range(base_count)])\n",
    "    tp_count = 0\n",
    "    tn_count = 0\n",
    "    fp_count = 0\n",
    "    fn_count = 0\n",
    "    \n",
    "    # Prepare predict data\n",
    "    for base_index, base_value in enumerate(base_vector):\n",
    "        for test_index, test_value in enumerate(test_vector):\n",
    "            similarity = cosine_similarity(base_value, test_value)\n",
    "\n",
    "            if similarity >= threshold:\n",
    "                predict_matrix[base_index][test_index] = 1 # 1 means duplicate\n",
    "            else:\n",
    "                predict_matrix[base_index][test_index] = 0 # 0 means non-duplicate\n",
    "    \n",
    "    # Calculate result\n",
    "    for i in range(base_count):\n",
    "        for j in range(test_count):\n",
    "            actual = actual_matrix[i][j]\n",
    "            predict = predict_matrix[i][j]\n",
    "\n",
    "            if actual == 0 and predict == 0: # true negative\n",
    "                tn_count += 1\n",
    "            elif actual == 1 and predict == 1: # true position\n",
    "                tp_count += 1\n",
    "            elif actual == 1 and predict == 0: # false negative \n",
    "                fn_count += 1\n",
    "            elif actual == 0 and predict == 1: # false positive\n",
    "                fp_count += 1\n",
    "\n",
    "    accuracy = (tn_count + tp_count) / (tn_count + tp_count + fn_count + fp_count)\n",
    "                \n",
    "    print(\"threshold:\", threshold)\n",
    "    print(\"true negative:\", tn_count)\n",
    "    print(\"true position:\", tp_count)\n",
    "    print(\"false negative:\", fn_count)\n",
    "    print(\"false positive:\", fp_count)\n",
    "    print(\"accuracy:\", accuracy)\n",
    "    print(\"\\n======================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base count: 94, Test count: 20, Total = 1880\n",
      "\n",
      "threshold: 0\n",
      "true negative: 1\n",
      "true position: 25\n",
      "false negative: 0\n",
      "false positive: 1854\n",
      "accuracy: 0.013829787234042552\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.1\n",
      "true negative: 32\n",
      "true position: 25\n",
      "false negative: 0\n",
      "false positive: 1823\n",
      "accuracy: 0.03031914893617021\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.2\n",
      "true negative: 172\n",
      "true position: 25\n",
      "false negative: 0\n",
      "false positive: 1683\n",
      "accuracy: 0.10478723404255319\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.3\n",
      "true negative: 543\n",
      "true position: 23\n",
      "false negative: 2\n",
      "false positive: 1312\n",
      "accuracy: 0.30106382978723406\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.4\n",
      "true negative: 1028\n",
      "true position: 18\n",
      "false negative: 7\n",
      "false positive: 827\n",
      "accuracy: 0.5563829787234043\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.5\n",
      "true negative: 1448\n",
      "true position: 14\n",
      "false negative: 11\n",
      "false positive: 407\n",
      "accuracy: 0.7776595744680851\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.6\n",
      "true negative: 1734\n",
      "true position: 7\n",
      "false negative: 18\n",
      "false positive: 121\n",
      "accuracy: 0.926063829787234\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.7\n",
      "true negative: 1838\n",
      "true position: 2\n",
      "false negative: 23\n",
      "false positive: 17\n",
      "accuracy: 0.9787234042553191\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.75\n",
      "true negative: 1852\n",
      "true position: 0\n",
      "false negative: 25\n",
      "false positive: 3\n",
      "accuracy: 0.9851063829787234\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.76\n",
      "true negative: 1854\n",
      "true position: 0\n",
      "false negative: 25\n",
      "false positive: 1\n",
      "accuracy: 0.9861702127659574\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.77\n",
      "true negative: 1854\n",
      "true position: 0\n",
      "false negative: 25\n",
      "false positive: 1\n",
      "accuracy: 0.9861702127659574\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.78\n",
      "true negative: 1855\n",
      "true position: 0\n",
      "false negative: 25\n",
      "false positive: 0\n",
      "accuracy: 0.9867021276595744\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.79\n",
      "true negative: 1855\n",
      "true position: 0\n",
      "false negative: 25\n",
      "false positive: 0\n",
      "accuracy: 0.9867021276595744\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.8\n",
      "true negative: 1855\n",
      "true position: 0\n",
      "false negative: 25\n",
      "false positive: 0\n",
      "accuracy: 0.9867021276595744\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 0.9\n",
      "true negative: 1855\n",
      "true position: 0\n",
      "false negative: 25\n",
      "false positive: 0\n",
      "accuracy: 0.9867021276595744\n",
      "\n",
      "======================================\n",
      "\n",
      "threshold: 1\n",
      "true negative: 1855\n",
      "true position: 0\n",
      "false negative: 25\n",
      "false positive: 0\n",
      "accuracy: 0.9867021276595744\n",
      "\n",
      "======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Base count: %d, Test count: %d, Total = %d\\n\" % (base_count, test_count, base_count * test_count))\n",
    "\n",
    "for threshold in thresholds:\n",
    "    calculate_similarity(threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
